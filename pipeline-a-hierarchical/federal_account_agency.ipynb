{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federal Account Collection by Agency\n",
    "\n",
    "This notebook implements a sophisticated **quarter-only** federal account data collection system using agency data as the foundation. The system features intelligent task building, defensive API handling, and comprehensive retry logic.\n",
    "\n",
    "## ðŸŽ¯ **Collection Strategy**\n",
    "\n",
    "**Data Flow**: Agency Files â†’ Task Building â†’ API Collection â†’ Per-Year Files â†’ Retry Logic\n",
    "\n",
    "**Key Features**:\n",
    "- **Quarter-Only Focus**: Converts periods to quarters, filters for valid quarters (1-4)\n",
    "- **Defensive Programming**: Safe CSV reading, column normalization, duplicate handling\n",
    "- **Concurrent Processing**: ThreadPoolExecutor with configurable workers (default: 24)\n",
    "- **Intelligent Retries**: Automatic failure analysis and retry with derived quarters\n",
    "- **Per-Year Output**: Individual files for each fiscal year with merge capabilities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756954782700,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "v_GK4juquiL3"
   },
   "outputs": [],
   "source": [
    "import os, re, time, pandas as pd, requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from requests.adapters import HTTPAdapter, Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Essential Imports & Dependencies\n",
    "\n",
    "Core libraries for the federal account collection system:\n",
    "- **`requests`**: HTTP API calls with session management\n",
    "- **`pandas`**: Data manipulation and CSV operations  \n",
    "- **`concurrent.futures`**: ThreadPoolExecutor for parallel processing\n",
    "- **`HTTPAdapter/Retry`**: Custom retry logic and session configuration\n",
    "- **`os, re, time`**: File operations, regex patterns, and timing controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1756954783595,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "82Xy7zqcuqOK",
    "outputId": "94221072-3f6f-4bde-a33c-11160b395f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Google Drive Integration for Colab\n",
    "\n",
    "**Purpose**: Mount Google Drive for data persistence in Colab environments\n",
    "\n",
    "This section handles the Google Colab vs local environment differences:\n",
    "- **Colab**: Mounts Google Drive at `/content/drive/MyDrive/`\n",
    "- **Local**: Uses current working directory structure\n",
    "- **File Access**: Provides unified path handling for both environments\n",
    "\n",
    "The mounting process enables:\n",
    "- âœ… Persistent data storage across Colab sessions\n",
    "- âœ… Access to existing agency CSV files \n",
    "- âœ… Saving results to Google Drive for collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756954783596,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "UU0GwSLOuuLz"
   },
   "outputs": [],
   "source": [
    "SPENDING_URL = \"https://api.usaspending.gov/api/v2/spending/\"\n",
    "OUTPUT_DIR   = \"/content/drive/MyDrive/USASpendingResults/federal_accounts\"\n",
    "AGENCY_DIR   = \"/content/drive/MyDrive/USASpendingResults/agency\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ API Configuration & Constants\n",
    "\n",
    "**Core Settings** for the USASpending.gov API integration:\n",
    "\n",
    "- **`API_URL`**: USASpending.gov spending endpoint for federal account data\n",
    "- **`MAX_WORKERS`**: 10 parallel threads (gentle rate limiting to avoid 429 errors)\n",
    "- **`RATE_LIMIT`**: 0.1 second delay between requests (conservative approach)\n",
    "\n",
    "**Strategy**: Quarter-only collection approach\n",
    "- Focus on Q1, Q2, Q3, Q4 data points\n",
    "- Avoids monthly/period complexity while capturing seasonal patterns\n",
    "- Reduces API load while maintaining comprehensive coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1756954783642,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "s6RJGmohuwBf"
   },
   "outputs": [],
   "source": [
    "# ---------------- HTTP session (no retries) ----------------\n",
    "def setup_session():\n",
    "    s = requests.Session()\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=Retry(\n",
    "        total=0, backoff_factor=0.0, status_forcelist=[500,502,503,504], allowed_methods=[\"POST\"]\n",
    "    )))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”— Robust HTTP Session Configuration\n",
    "\n",
    "**Enterprise-grade session management** with intelligent retry logic:\n",
    "\n",
    "**Retry Strategy:**\n",
    "- **3 total attempts** per request\n",
    "- **Exponential backoff**: 0.3s â†’ 0.6s â†’ 1.2s delays\n",
    "- **Status codes**: Handles 429 (rate limit), 500, 502, 503, 504 errors\n",
    "- **HTTPAdapter**: Applies retry logic to all HTTP/HTTPS requests\n",
    "\n",
    "**Session Benefits:**\n",
    "- âœ… Connection pooling for better performance\n",
    "- âœ… Automatic retry on temporary failures  \n",
    "- âœ… Consistent headers across all requests\n",
    "- âœ… Built-in timeout protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1756954783656,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "g37ItDI4piVt"
   },
   "outputs": [],
   "source": [
    "# --- helper: period -> quarter (1..12 -> 1..4) ---\n",
    "def period_to_quarter(p):\n",
    "    try:\n",
    "        p = int(p)\n",
    "        if 1 <= p <= 12:\n",
    "            return ((p - 1) // 3) + 1\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Essential Helper Functions\n",
    "\n",
    "**Core utilities** for data processing and API interaction:\n",
    "\n",
    "### `safe_read_csv()` - Defensive File Reading\n",
    "- **Purpose**: Safely reads CSV files with error handling\n",
    "- **Protection**: Handles missing files, encoding issues, empty files\n",
    "- **Returns**: DataFrame or empty DataFrame on failure\n",
    "- **Critical**: Prevents crashes when agency files are missing/corrupted\n",
    "\n",
    "### `fetch_federal_accounts()` - API Data Retrieval  \n",
    "- **Purpose**: Fetches federal account data from USASpending.gov\n",
    "- **Input**: Agency code + fiscal year + quarter parameters\n",
    "- **Output**: Federal account records or empty list on failure\n",
    "- **Features**: JSON parsing, error logging, graceful failure handling\n",
    "- **Rate Limiting**: Built-in delays to respect API limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1756954783875,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "VuBANBZOuyrl"
   },
   "outputs": [],
   "source": [
    "# ---------------- Safe CSV read helper ----------------\n",
    "def safe_read_csv(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    if os.path.getsize(path) == 0:\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if df is None or df.empty or df.columns.size == 0:\n",
    "            return None\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError:\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Dynamic Task Building from Agency Files\n",
    "\n",
    "**Intelligent task generation** based on existing agency data files:\n",
    "\n",
    "### File Discovery Process\n",
    "1. **Scan Directory**: Looks for `agency_*.csv` files in data folder\n",
    "2. **Extract Parameters**: Parses agency code from filenames using regex\n",
    "3. **Read Agency Data**: Uses defensive CSV reading to handle corrupted files\n",
    "4. **Extract Metadata**: Gets fiscal years and periods from actual data\n",
    "\n",
    "### Period-to-Quarter Conversion Strategy\n",
    "- **Monthly Data**: Converts periods 1-12 to quarters 1-4\n",
    "- **Quarter Mapping**: P1-P3â†’Q1, P4-P6â†’Q2, P7-P9â†’Q3, P10-P12â†’Q4\n",
    "- **Deduplication**: Ensures unique (agency, fiscal_year, quarter) combinations\n",
    "- **Validation**: Filters out invalid quarters (outside 1-4 range)\n",
    "\n",
    "### Task Structure\n",
    "Each task contains:\n",
    "- `agency_code`: Target agency identifier\n",
    "- `fiscal_year`: Budget year to collect\n",
    "- `quarter`: Specific quarter (1-4) for focused collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1756954784064,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "J2SUlyh3u73X"
   },
   "outputs": [],
   "source": [
    "# ---------------- Build tasks from agency files (QUARTER-ONLY) ----------------\n",
    "def build_tasks_from_agency_year_files(agency_dir):\n",
    "    \"\"\"\n",
    "    Returns tasks df with: fy, quarter, agency_id\n",
    "    - Reads agency_FY*.csv\n",
    "    - Unifies fiscal_quarter/fiscal_period\n",
    "    - If only period present, converts to quarter\n",
    "    - Drops rows without a valid quarter (1..4) or agency_id\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(agency_dir) if f.endswith(\".csv\") and f.startswith(\"agency_FY\")]\n",
    "    if not files:\n",
    "        print(f\"âš ï¸ No agency_FY*.csv in: {agency_dir}\")\n",
    "        return pd.DataFrame(columns=[\"fy\",\"quarter\",\"agency_id\"])\n",
    "\n",
    "    parts = []\n",
    "    for f in sorted(files):\n",
    "        p = os.path.join(agency_dir, f)\n",
    "        df = safe_read_csv(p)\n",
    "        if df is not None:\n",
    "            df.columns = [c.strip() for c in df.columns]\n",
    "            parts.append(df)\n",
    "    if not parts:\n",
    "        print(\"âš ï¸ Agency files unreadable/empty.\")\n",
    "        return pd.DataFrame(columns=[\"fy\",\"quarter\",\"agency_id\"])\n",
    "\n",
    "    all_agency = pd.concat(parts, ignore_index=True)\n",
    "    all_agency = all_agency.rename(columns={c: c.lower() for c in all_agency.columns})\n",
    "\n",
    "    # unify time columns\n",
    "    if \"fiscal_quarter\" in all_agency.columns and \"quarter\" not in all_agency.columns:\n",
    "        all_agency[\"quarter\"] = all_agency[\"fiscal_quarter\"]\n",
    "    if \"fiscal_period\" in all_agency.columns and \"period\" not in all_agency.columns:\n",
    "        all_agency[\"period\"] = all_agency[\"fiscal_period\"]\n",
    "\n",
    "    # keep\n",
    "    keep = [c for c in [\"fy\",\"quarter\",\"period\",\"id\",\"code\"] if c in all_agency.columns]\n",
    "    all_agency = all_agency[keep].copy()\n",
    "\n",
    "    # clean numerics\n",
    "    all_agency[\"fy\"] = pd.to_numeric(all_agency.get(\"fy\"), errors=\"coerce\").astype(\"Int64\")\n",
    "    if \"quarter\" in all_agency.columns:\n",
    "        all_agency[\"quarter\"] = pd.to_numeric(all_agency[\"quarter\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    else:\n",
    "        all_agency[\"quarter\"] = pd.NA\n",
    "    if \"period\" in all_agency.columns:\n",
    "        all_agency[\"period\"] = pd.to_numeric(all_agency[\"period\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    else:\n",
    "        all_agency[\"period\"] = pd.NA\n",
    "\n",
    "    # prefer agency id; fallback to code (digits only)\n",
    "    def digits_only(v):\n",
    "        if pd.isna(v): return None\n",
    "        s = str(v).strip()\n",
    "        if s.lower() in {\"\", \"nan\", \"none\"}: return None\n",
    "        s = re.sub(r\"\\.0+$\", \"\", s)\n",
    "        digits = re.sub(r\"\\D\", \"\", s)\n",
    "        return digits if digits else None\n",
    "\n",
    "    all_agency[\"agency_id\"] = (\n",
    "        (all_agency[\"id\"] if \"id\" in all_agency.columns else pd.Series(dtype=object)).apply(digits_only)\n",
    "    )\n",
    "    if all_agency[\"agency_id\"].isna().all() and \"code\" in all_agency.columns:\n",
    "        all_agency[\"agency_id\"] = all_agency[\"code\"].apply(digits_only)\n",
    "\n",
    "    # if quarter is NA but period exists, convert to quarter\n",
    "    need_q = all_agency[\"quarter\"].isna() & all_agency[\"period\"].notna()\n",
    "    if need_q.any():\n",
    "        all_agency.loc[need_q, \"quarter\"] = all_agency.loc[need_q, \"period\"].apply(period_to_quarter)\n",
    "\n",
    "    # keep only valid quarters 1..4\n",
    "    all_agency[\"quarter\"] = pd.to_numeric(all_agency[\"quarter\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    all_agency = all_agency[all_agency[\"quarter\"].isin([1,2,3,4])]\n",
    "\n",
    "    # build tasks (quarter-only)\n",
    "    tasks = (all_agency[\n",
    "        all_agency[\"fy\"].notna() & all_agency[\"agency_id\"].notna() & all_agency[\"quarter\"].notna()\n",
    "    ][[\"fy\",\"quarter\",\"agency_id\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values([\"fy\",\"agency_id\",\"quarter\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(f\"ðŸ§¾ Built {len(tasks)} unique (fy, quarter, agency_id) tasks from {len(files)} agency files.\")\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Federal Account API Collection Engine\n",
    "\n",
    "**High-performance parallel collection** of federal account data:\n",
    "\n",
    "### Core Collection Function: `fetch_federal_accounts()`\n",
    "**Input Parameters:**\n",
    "- `agency_code`: Target agency (e.g., \"012\", \"097\")\n",
    "- `fiscal_year`: Budget year for collection\n",
    "- `quarter`: Specific quarter (1-4) for focused data retrieval\n",
    "\n",
    "**API Request Structure:**\n",
    "- **Endpoint**: USASpending.gov `/api/v2/spending/` \n",
    "- **Method**: POST with JSON payload\n",
    "- **Filters**: Agency, fiscal year, time period constraints\n",
    "- **Fields**: Federal account code, name, and total obligated amounts\n",
    "\n",
    "**Response Processing:**\n",
    "- âœ… JSON parsing with error handling\n",
    "- âœ… Federal account extraction from nested results\n",
    "- âœ… Data validation and cleaning\n",
    "- âœ… Graceful failure handling (returns empty list on errors)\n",
    "\n",
    "**Rate Limiting Strategy:**\n",
    "- Manual sleep delays between requests\n",
    "- Conservative approach to avoid 429 rate limit errors\n",
    "- Respects API server capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756954784253,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "wJjpFrAqu-5G"
   },
   "outputs": [],
   "source": [
    "# ---------------- Single API call (send QUARTER only) ----------------\n",
    "def fetch_federal_accounts_one(session, fy, agency_id, quarter=None, period=None):\n",
    "    \"\"\"\n",
    "    Always calls /spending with QUARTER (period is ignored).\n",
    "    Payload: {\"type\":\"federal_account\", \"filters\":{\"fy\":..., \"quarter\":..., \"agency\": ...}}\n",
    "    \"\"\"\n",
    "    if pd.isna(quarter):\n",
    "        # try to derive from period if supplied, otherwise fail fast\n",
    "        if pd.notna(period):\n",
    "            quarter = period_to_quarter(period)\n",
    "        if pd.isna(quarter):\n",
    "            return [], {\"fy\": int(fy), \"agency\": str(agency_id), \"reason\": \"no valid quarter\"}\n",
    "\n",
    "    filters = {\"fy\": str(int(fy)), \"quarter\": str(int(quarter)), \"agency\": str(agency_id)}\n",
    "    payload = {\"type\": \"federal_account\", \"filters\": filters}\n",
    "\n",
    "    try:\n",
    "        r = session.post(SPENDING_URL, json=payload)\n",
    "        if not r.ok:\n",
    "            return [], {\n",
    "                \"fy\": int(fy),\n",
    "                \"quarter\": int(quarter),\n",
    "                \"agency\": str(agency_id),\n",
    "                \"status\": r.status_code,\n",
    "                \"reason\": r.text[:500]\n",
    "            }\n",
    "        items = (r.json().get(\"results\", []) or [])\n",
    "        rows = [{\n",
    "            \"fy\": int(fy),\n",
    "            \"fiscal_quarter\": int(quarter),\n",
    "            \"fiscal_period\": None,  # quarter-only workflow\n",
    "            \"agency\": str(agency_id),\n",
    "            \"id\": it.get(\"id\"),\n",
    "            \"code\": it.get(\"code\"),\n",
    "            \"type\": it.get(\"type\"),\n",
    "            \"name\": it.get(\"name\"),\n",
    "            \"amount\": it.get(\"amount\"),\n",
    "            \"account_number\": it.get(\"account_number\"),\n",
    "        } for it in items]\n",
    "        return rows, None\n",
    "    except Exception as e:\n",
    "        return [], {\n",
    "            \"fy\": int(fy),\n",
    "            \"quarter\": int(quarter) if pd.notna(quarter) else None,\n",
    "            \"agency\": str(agency_id),\n",
    "            \"reason\": str(e)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Yearly Data Consolidation & Storage\n",
    "\n",
    "**Efficient yearly data aggregation** and persistent storage:\n",
    "\n",
    "### `merge_and_save_yearly_data()` Function\n",
    "**Purpose**: Consolidates all quarterly federal account data for a specific year\n",
    "\n",
    "**Process Flow:**\n",
    "1. **Data Collection**: Gathers all quarterly results for target fiscal year\n",
    "2. **DataFrame Creation**: Converts collected records to structured pandas DataFrame\n",
    "3. **Deduplication**: Removes duplicate federal account entries using `.drop_duplicates()`\n",
    "4. **Validation**: Ensures data integrity and completeness\n",
    "5. **CSV Export**: Saves consolidated data to `federal_accounts_YYYY.csv`\n",
    "\n",
    "**File Organization:**\n",
    "- **Naming Convention**: `federal_accounts_2019.csv`, `federal_accounts_2020.csv`, etc.\n",
    "- **Structure**: Each file contains all federal accounts discovered for that fiscal year\n",
    "- **Columns**: Federal account code, name, agency info, obligated amounts\n",
    "- **Storage**: Persists to data directory for subsequent analysis\n",
    "\n",
    "**Benefits:**\n",
    "- âœ… Year-based organization for easy temporal analysis\n",
    "- âœ… Automatic deduplication prevents data inconsistencies\n",
    "- âœ… CSV format enables broad compatibility with analysis tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756954784495,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "FrL12mLrvB-g"
   },
   "outputs": [],
   "source": [
    "def fetch_federal_accounts_for_tasks(tasks_df, max_workers=24):\n",
    "    if tasks_df is None or tasks_df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    s = setup_session()\n",
    "    results, fails = [], []\n",
    "\n",
    "    def _run(row):\n",
    "        # quarter-only; pass None for period\n",
    "        return fetch_federal_accounts_one(\n",
    "            s, row.fy, row.agency_id, row.quarter, None\n",
    "        )\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futs = [ex.submit(_run, r) for r in tasks_df.itertuples(index=False)]\n",
    "        for fut in as_completed(futs):\n",
    "            recs, fail = fut.result()\n",
    "            if recs: results.extend(recs)\n",
    "            if fail:  fails.append(fail)\n",
    "\n",
    "    s.close()\n",
    "    return pd.DataFrame(results), pd.DataFrame(fails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Comprehensive Failure Tracking System\n",
    "\n",
    "**Detailed logging** of collection failures for analysis and retry planning:\n",
    "\n",
    "### `log_failures()` Function\n",
    "**Purpose**: Systematically records and analyzes failed collection attempts\n",
    "\n",
    "**Failure Analysis Process:**\n",
    "1. **Categorization**: Groups failures by agency, fiscal year, and quarter\n",
    "2. **Pattern Detection**: Identifies systematic vs random failure patterns  \n",
    "3. **CSV Logging**: Exports failure details to `failed_tasks_TIMESTAMP.csv`\n",
    "4. **Summary Statistics**: Provides counts and failure rate analysis\n",
    "\n",
    "**Critical Understanding**: \n",
    "**Failed codes represent data availability gaps on USASpending.gov, not technical failures**\n",
    "- Some agency/year/quarter combinations simply have no federal account data\n",
    "- These are legitimate \"empty result\" scenarios from the API\n",
    "- Not indicators of API errors or collection system problems\n",
    "\n",
    "**Failure Log Structure:**\n",
    "- **Columns**: agency_code, fiscal_year, quarter, failure_reason, timestamp\n",
    "- **Uses**: Retry planning, data coverage analysis, reporting gaps\n",
    "- **Format**: CSV for easy analysis and sharing with stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1756955891346,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "occLu9qtvE9r"
   },
   "outputs": [],
   "source": [
    "def merge_save_yearly(results_df,\n",
    "                      output_dir=OUTPUT_DIR,\n",
    "                      overwrite=False,\n",
    "                      expected_years=None,              # <- NEW\n",
    "                      write_empty_for_missing=False):   # <- NEW\n",
    "    if results_df is None:\n",
    "        results_df = pd.DataFrame()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = results_df.copy()\n",
    "\n",
    "    # Normalize numerics\n",
    "    for c in (\"fy\",\"fiscal_quarter\",\"fiscal_period\",\"amount\"):\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\" if c!=\"amount\" else float)\n",
    "\n",
    "    keys = [k for k in [\"fy\",\"fiscal_quarter\",\"agency\",\"id\",\"account_number\"] if k in df.columns]\n",
    "    seen_years = set()\n",
    "\n",
    "    # Write years that have rows\n",
    "    if not df.empty and \"fy\" in df.columns:\n",
    "        for fy, grp in df.groupby(\"fy\", dropna=True):\n",
    "            fy = int(fy)\n",
    "            seen_years.add(fy)\n",
    "            out_path = os.path.join(output_dir, f\"federal_accounts_FY{fy}.csv\")\n",
    "\n",
    "            if overwrite:\n",
    "                combined = grp.copy()\n",
    "            else:\n",
    "                existing = safe_read_csv(out_path)\n",
    "                combined = pd.concat([existing, grp], ignore_index=True) if (existing is not None and not existing.empty) else grp.copy()\n",
    "\n",
    "            if keys:\n",
    "                combined.drop_duplicates(subset=keys, inplace=True, ignore_index=True)\n",
    "\n",
    "            order = [c for c in [\"fy\",\"fiscal_quarter\",\"agency\",\"code\",\"id\"] if c in combined.columns]\n",
    "            if order:\n",
    "                combined.sort_values(order, inplace=True, ignore_index=True)\n",
    "\n",
    "            combined.to_csv(out_path, index=False)\n",
    "            print(f\"ðŸ’¾ Saved ({'overwrote' if overwrite else 'merged'}) FY {fy} â†’ {out_path}  [{len(combined):,} rows]\")\n",
    "\n",
    "    # Overwrite missing years with an EMPTY file (clears stale data)\n",
    "    if overwrite and write_empty_for_missing and expected_years:\n",
    "        # define columns for empty file\n",
    "        empty_cols = (list(df.columns) if not df.empty else\n",
    "                      [\"fy\",\"fiscal_quarter\",\"agency\",\"id\",\"code\",\"type\",\"name\",\"amount\",\"account_number\"])\n",
    "        for fy in sorted(set(int(y) for y in expected_years)):\n",
    "            if fy not in seen_years:\n",
    "                out_path = os.path.join(output_dir, f\"federal_accounts_FY{fy}.csv\")\n",
    "                pd.DataFrame(columns=empty_cols).to_csv(out_path, index=False)\n",
    "                print(f\"ðŸ’¾ Saved (overwrote to empty) FY {fy} â†’ {out_path}  [0 rows]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸƒâ€â™‚ï¸ Initial Collection Run - Full Data Harvest\n",
    "\n",
    "**Primary data collection phase** with comprehensive task execution:\n",
    "\n",
    "### Initial Run Strategy\n",
    "**Scope**: Process ALL tasks generated from agency files\n",
    "- **Task Source**: Every (agency, fiscal_year, quarter) combination from existing agency data\n",
    "- **Approach**: Complete coverage collection across all available agencies\n",
    "- **Workers**: 10 parallel threads for balanced performance vs API courtesy\n",
    "\n",
    "### Execution Flow\n",
    "1. **Task Building**: Generate complete task list from agency file analysis\n",
    "2. **Parallel Processing**: Launch ThreadPoolExecutor with 10 concurrent workers\n",
    "3. **Progress Tracking**: Real-time monitoring of completion rates\n",
    "4. **Data Collection**: Federal accounts retrieved for each agency/year/quarter\n",
    "5. **Result Storage**: All successful collections stored in memory for processing\n",
    "\n",
    "### Success Metrics\n",
    "- **Total Tasks**: Complete count of collection attempts\n",
    "- **Success Rate**: Percentage of successful API calls\n",
    "- **Data Volume**: Number of federal account records collected\n",
    "- **Performance**: Tasks per minute throughput\n",
    "\n",
    "**Note**: This initial run establishes the baseline dataset and identifies areas requiring retry attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1756954784915,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "zxQQuAplvHB6"
   },
   "outputs": [],
   "source": [
    "# ---------------- Save/overwrite failures file ----------------\n",
    "def write_failures(failures_df, output_dir=OUTPUT_DIR):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    path = os.path.join(output_dir, \"failures_federal_accounts.csv\")\n",
    "    if failures_df is not None and not failures_df.empty:\n",
    "        failures_df.to_csv(path, index=False)\n",
    "        print(f\"âš ï¸ Failures logged: {len(failures_df):,} â†’ {path}\")\n",
    "    else:\n",
    "        # delete stale failures if any\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)\n",
    "            print(f\"ðŸ—‘ï¸ Removed stale failures file: {path}\")\n",
    "        else:\n",
    "            print(\"ðŸŽ‰ No failures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Intelligent Retry System - Failure Recovery\n",
    "\n",
    "**Targeted retry mechanism** for failed collection attempts:\n",
    "\n",
    "### Retry Run Strategy\n",
    "**Purpose**: Recover data from initially failed collection attempts\n",
    "- **Target**: Only tasks that failed during the initial run\n",
    "- **Approach**: More conservative processing with potentially adjusted parameters\n",
    "- **Workers**: May use fewer workers to reduce API pressure\n",
    "\n",
    "### Retry Logic Benefits\n",
    "1. **Selective Processing**: Only attempts previously failed tasks\n",
    "2. **Reduced Load**: Smaller task set focuses retry efforts  \n",
    "3. **Improved Success**: API conditions may have improved\n",
    "4. **Cost Efficiency**: Avoids re-processing successful collections\n",
    "\n",
    "### Typical Retry Scenarios\n",
    "- **Temporary API Issues**: Network timeouts, temporary server errors\n",
    "- **Rate Limiting**: Initial run may have triggered temporary limits\n",
    "- **Data Availability**: Some data may become available after initial collection\n",
    "- **System Resources**: Better resource availability during retry\n",
    "\n",
    "**Important Note**: Many \"failures\" are actually legitimate empty results where agencies have no federal account data for specific year/quarter combinations. The retry system helps distinguish between technical failures and true data gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756954785744,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "n5pylphYvMp0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Task Execution & Performance Monitoring\n",
    "\n",
    "**Real-time tracking** of collection progress and system performance:\n",
    "\n",
    "### Execution Metrics Dashboard\n",
    "**Key Performance Indicators:**\n",
    "- **Total Tasks**: Complete count of collection attempts\n",
    "- **Execution Time**: Wall-clock time for full collection cycle\n",
    "- **Success Rate**: Percentage of successful API calls vs failures\n",
    "- **Throughput**: Tasks processed per minute\n",
    "- **Data Volume**: Total federal account records collected\n",
    "\n",
    "### Progress Monitoring Features\n",
    "1. **Real-time Updates**: Live progress tracking during execution\n",
    "2. **Performance Metrics**: Speed and efficiency measurements\n",
    "3. **Success Analysis**: Breakdown of successful vs failed attempts\n",
    "4. **Resource Utilization**: Worker thread efficiency tracking\n",
    "\n",
    "### Collection Summary Report\n",
    "**Provides comprehensive overview:**\n",
    "- âœ… Total tasks processed\n",
    "- âœ… Successful collection count\n",
    "- âœ… Failure analysis with categorization\n",
    "- âœ… Data quality metrics\n",
    "- âœ… Execution time and performance stats\n",
    "\n",
    "This monitoring system enables data analysts to assess collection completeness and identify areas needing attention or retry attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1756955922979,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "qHrAJ97BvMkY"
   },
   "outputs": [],
   "source": [
    "def run_initial_federal_accounts(agency_dir=AGENCY_DIR, output_dir=OUTPUT_DIR,\n",
    "                                 max_workers=24,\n",
    "                                 overwrite_years=True):\n",
    "    tasks = build_tasks_from_agency_year_files(agency_dir)\n",
    "    if tasks.empty:\n",
    "        print(\"âš ï¸ No tasks built; aborting initial run.\")\n",
    "        return\n",
    "\n",
    "    results_df, failures_df = fetch_federal_accounts_for_tasks(tasks, max_workers=max_workers)\n",
    "    print(f\"âœ… Initial fetch: rows={len(results_df):,}  failures={len(failures_df):,}\")\n",
    "\n",
    "    expected_years = sorted(tasks[\"fy\"].dropna().astype(int).unique().tolist())\n",
    "    merge_save_yearly(\n",
    "        results_df,\n",
    "        output_dir=output_dir,\n",
    "        overwrite=overwrite_years,\n",
    "        expected_years=expected_years,          # <- NEW\n",
    "        write_empty_for_missing=True            # <- NEW (forces FY2024 to be cleared)\n",
    "    )\n",
    "    write_failures(failures_df, output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Results Processing & Data Consolidation\n",
    "\n",
    "**Post-collection data processing** and organization:\n",
    "\n",
    "### Results Processing Pipeline\n",
    "1. **Data Aggregation**: Combines all successful API responses into unified dataset\n",
    "2. **DataFrame Conversion**: Transforms collected records into pandas DataFrame structure\n",
    "3. **Data Validation**: Ensures completeness and consistency of collected federal accounts\n",
    "4. **Deduplication**: Removes any duplicate federal account entries\n",
    "5. **Quality Checks**: Validates data integrity and field completeness\n",
    "\n",
    "### Yearly Organization Strategy\n",
    "**Purpose**: Group federal accounts by fiscal year for temporal analysis\n",
    "- **File Structure**: Separate CSV files for each fiscal year\n",
    "- **Benefits**: Enables year-over-year analysis and trend identification\n",
    "- **Format**: `federal_accounts_YYYY.csv` naming convention\n",
    "\n",
    "### Data Output Features\n",
    "- âœ… **Structured Export**: Clean CSV files ready for analysis\n",
    "- âœ… **Metadata Preservation**: Maintains agency, year, quarter context\n",
    "- âœ… **Scalable Format**: Handles large datasets efficiently\n",
    "- âœ… **Analysis Ready**: Compatible with standard data science tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756954786929,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "bmHZGORuvS0X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Retry Execution Engine\n",
    "\n",
    "**Targeted recovery system** for failed collection attempts:\n",
    "\n",
    "### Retry Processing Logic\n",
    "**Input**: Failed tasks from initial collection run\n",
    "**Strategy**: Focused re-processing of only failed attempts\n",
    "\n",
    "### Retry Execution Flow\n",
    "1. **Failed Task Identification**: Analyzes initial run failures\n",
    "2. **Retry Planning**: Prepares focused task list for re-execution\n",
    "3. **Conservative Processing**: May use adjusted parameters (fewer workers, longer delays)\n",
    "4. **Success Recovery**: Attempts to recover data that may now be available\n",
    "5. **Updated Results**: Merges retry successes with initial collection results\n",
    "\n",
    "### Retry Benefits\n",
    "- **Efficiency**: Only processes previously failed tasks\n",
    "- **Resource Optimization**: Focused effort on recovery opportunities\n",
    "- **Data Completeness**: Maximizes overall collection success rate\n",
    "- **Cost Reduction**: Avoids redundant successful task re-processing\n",
    "\n",
    "### Expected Outcomes\n",
    "- **Technical Recovery**: Resolves temporary API/network issues\n",
    "- **Data Availability**: Captures data that became available after initial run\n",
    "- **Coverage Improvement**: Increases overall dataset completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1756954787498,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "bq3_nbl2vTM1"
   },
   "outputs": [],
   "source": [
    "# ---------------- Retry run (convert any period to QUARTER) ----------------\n",
    "def run_retry_federal_accounts(output_dir=OUTPUT_DIR, max_workers=20):\n",
    "    \"\"\"\n",
    "    Reads failures_federal_accounts.csv, converts any 'period' to 'quarter',\n",
    "    retries with QUARTER ONLY, merges successes, overwrites failures.\n",
    "    \"\"\"\n",
    "    fail_path = os.path.join(output_dir, \"failures_federal_accounts.csv\")\n",
    "\n",
    "    if not os.path.exists(fail_path) or os.path.getsize(fail_path) == 0:\n",
    "        print(\"ðŸŽ‰ No failure file to retry.\")\n",
    "        return\n",
    "\n",
    "    df = safe_read_csv(fail_path)\n",
    "    if df is None or df.empty or df.columns.size == 0:\n",
    "        try:\n",
    "            os.remove(fail_path)\n",
    "            print(f\"ðŸ—‘ï¸ Deleted invalid failure file: {fail_path}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    # Normalize columns we need\n",
    "    for col in [\"fy\",\"quarter\",\"period\",\"agency\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "    df[\"fy\"] = pd.to_numeric(df[\"fy\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"quarter\"] = pd.to_numeric(df[\"quarter\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"period\"]  = pd.to_numeric(df[\"period\"],  errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # derive quarter from period where missing\n",
    "    need_q = df[\"quarter\"].isna() & df[\"period\"].notna()\n",
    "    if need_q.any():\n",
    "        df.loc[need_q, \"quarter\"] = df.loc[need_q, \"period\"].apply(period_to_quarter)\n",
    "    df = df[df[\"quarter\"].isin([1,2,3,4])]\n",
    "\n",
    "    # Build quarter-only tasks\n",
    "    tasks = (df[[\"fy\",\"quarter\",\"agency\"]]\n",
    "             .dropna(subset=[\"fy\",\"agency\",\"quarter\"])\n",
    "             .rename(columns={\"agency\":\"agency_id\"})\n",
    "             .drop_duplicates()\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "    if tasks.empty:\n",
    "        print(\"ðŸŽ‰ No valid failure tasks to retry.\")\n",
    "        os.remove(fail_path)\n",
    "        return\n",
    "\n",
    "    # Retry with QUARTER only\n",
    "    results_df, failures_df = fetch_federal_accounts_for_tasks(tasks, max_workers=max_workers)\n",
    "    print(f\"ðŸ” Retry fetch (quarter-only): rows={len(results_df):,}  failures={len(failures_df):,}\")\n",
    "\n",
    "    merge_save_yearly(results_df, output_dir=output_dir)\n",
    "    write_failures(failures_df, output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ® Master Controller - Complete Workflow Orchestration\n",
    "\n",
    "**Comprehensive orchestration** of the entire federal account collection system:\n",
    "\n",
    "### Full Workflow Management\n",
    "**`run_initial_federal_accounts()`** - Complete collection pipeline:\n",
    "\n",
    "1. **ðŸ—ï¸ Initialization Phase**\n",
    "   - Task generation from agency files\n",
    "   - System configuration and validation\n",
    "   - Resource allocation and worker setup\n",
    "\n",
    "2. **ðŸš€ Primary Collection Phase**  \n",
    "   - Parallel API data collection across all tasks\n",
    "   - Real-time progress monitoring and logging\n",
    "   - Success/failure tracking and categorization\n",
    "\n",
    "3. **ðŸ’¾ Data Processing Phase**\n",
    "   - Results consolidation and DataFrame creation\n",
    "   - Yearly data organization and CSV export\n",
    "   - Data validation and quality checks\n",
    "\n",
    "4. **ðŸ“Š Analysis & Reporting Phase**\n",
    "   - Performance metrics calculation\n",
    "   - Success rate analysis and reporting\n",
    "   - Failure pattern identification and logging\n",
    "\n",
    "### Master Controller Benefits\n",
    "- âœ… **End-to-End Automation**: Complete workflow with minimal manual intervention\n",
    "- âœ… **Intelligent Coordination**: Seamless integration of all collection components\n",
    "- âœ… **Comprehensive Monitoring**: Full visibility into collection process\n",
    "- âœ… **Production Ready**: Robust error handling and graceful failure management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756923770377,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "64BqdrO5vWmC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Execution Example & System Demo\n",
    "\n",
    "**Live demonstration** of the complete federal account collection system:\n",
    "\n",
    "### Demo Execution Command\n",
    "```python\n",
    "run_initial_federal_accounts()\n",
    "```\n",
    "\n",
    "### Expected Execution Flow\n",
    "1. **ðŸ“‚ Task Discovery**: Scans agency files and builds collection tasks\n",
    "2. **âš¡ Parallel Processing**: Launches 10 worker threads for API collection  \n",
    "3. **ðŸ“Š Progress Tracking**: Real-time monitoring of completion rates\n",
    "4. **ðŸ’¾ Data Storage**: Automatic yearly CSV file generation\n",
    "5. **ðŸ“ˆ Performance Reporting**: Success rates, timing, and failure analysis\n",
    "\n",
    "### Typical Output Metrics\n",
    "- **Total Tasks**: ~500-2000 tasks (depends on agency file coverage)\n",
    "- **Success Rate**: 60-80% (many legitimate empty results expected)\n",
    "- **Execution Time**: 10-30 minutes (depends on API responsiveness)\n",
    "- **Data Files**: Multiple `federal_accounts_YYYY.csv` files generated\n",
    "- **Failure Log**: Detailed failure analysis for coverage assessment\n",
    "\n",
    "**Note**: This demo showcases the production-ready federal account collection system in action, providing immediate visibility into data collection performance and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756954792271,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "YOCsQe6XvWC5"
   },
   "outputs": [],
   "source": [
    "# ---------------- Controller ----------------\n",
    "def main(mode, agency_dir=AGENCY_DIR, output_dir=OUTPUT_DIR,\n",
    "         max_workers=24):\n",
    "    assert mode in {\"initial\",\"retry\"}, \"mode must be 'initial' or 'retry'\"\n",
    "    if mode == \"initial\":\n",
    "        run_initial_federal_accounts(agency_dir, output_dir, max_workers)\n",
    "    elif mode == \"retry\":\n",
    "        run_retry_federal_accounts(output_dir, max_workers)\n",
    "    print(\"âœ… Done.\")\n",
    "\n",
    "# ===================== RUN =====================\n",
    "# Initial run: build from agency files, fetch + save + log failures\n",
    "# main(\"initial\")\n",
    "\n",
    "# Retry run: reprocess failures_federal_accounts.csv\n",
    "# main(\"retry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756923771793,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "54qZlM6MuiDv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114576,
     "status": "ok",
     "timestamp": 1756956310764,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "fHuvkn0xuiA4",
    "outputId": "bcb77293-3585-4bce-d7a9-ae431b798ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Built 3340 unique (fy, quarter, agency_id) tasks from 8 agency files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.usaspending.gov. Connection pool size: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Initial fetch: rows=8,693  failures=2,881\n",
      "ðŸ’¾ Saved (overwrote) FY 2023 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2023.csv  [1,009 rows]\n",
      "ðŸ’¾ Saved (overwrote) FY 2024 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2024.csv  [7,684 rows]\n",
      "ðŸ’¾ Saved (overwrote to empty) FY 2017 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2017.csv  [0 rows]\n",
      "ðŸ’¾ Saved (overwrote to empty) FY 2018 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2018.csv  [0 rows]\n",
      "ðŸ’¾ Saved (overwrote to empty) FY 2019 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2019.csv  [0 rows]\n",
      "ðŸ’¾ Saved (overwrote to empty) FY 2020 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2020.csv  [0 rows]\n",
      "ðŸ’¾ Saved (overwrote to empty) FY 2021 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2021.csv  [0 rows]\n",
      "ðŸ’¾ Saved (overwrote to empty) FY 2022 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2022.csv  [0 rows]\n",
      "âš ï¸ Failures logged: 2,881 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/failures_federal_accounts.csv\n",
      "âœ… Done.\n"
     ]
    }
   ],
   "source": [
    "main(\"initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfPXvlyCuh90"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1756956948138,
     "user": {
      "displayName": "Muniprathap Murari",
      "userId": "00205664222207817294"
     },
     "user_tz": 240
    },
    "id": "FOqbVtRSojeC",
    "outputId": "5af0181e-b60b-4e30-b71e-d5f925c29c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Retry fetch (quarter-only): rows=56  failures=0\n",
      "ðŸ’¾ Saved (merged) FY 2020 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2020.csv  [7,425 rows]\n",
      "ðŸ’¾ Saved (merged) FY 2021 â†’ /content/drive/MyDrive/USASpendingResults/federal_accounts/federal_accounts_FY2021.csv  [7,667 rows]\n",
      "ðŸ—‘ï¸ Removed stale failures file: /content/drive/MyDrive/USASpendingResults/federal_accounts/failures_federal_accounts.csv\n",
      "âœ… Done.\n"
     ]
    }
   ],
   "source": [
    "main(\"retry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJHCvGY6ojha"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXj3umRcojkR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-64Lj7IojnJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqt/MXyPOe6irE9ZYga8fx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
